{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow intro\n",
    "\n",
    "This tutorial shows the basic usage of tensorflow to train neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Read data and convert them to numerical inputs\n",
    "Vytvárame dáta: X(matica rozmerov počet pozorovaní krát dimenzionalita dát)->inputy, y(vektor, pre každé pozorovanie máme jednu hodnotu)-> outputy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=20000, n_features=8, n_informative=5, \n",
    "                           n_redundant=0, n_classes=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (12800, 8), target_ratio: 0.502\n",
      "test size: (4000, 8), target_ratio: 0.501\n",
      "dev size: (3200, 8), target_ratio: 0.502\n"
     ]
    }
   ],
   "source": [
    "print('train size: {}, target_ratio: {:.3f}'.format(X_train.shape, np.mean(y_train)))\n",
    "print('test size: {}, target_ratio: {:.3f}'.format(X_test.shape, np.mean(y_test)))\n",
    "print('dev size: {}, target_ratio: {:.3f}'.format(X_dev.shape, np.mean(y_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very useful documentations with many examples and detailed explanation of everything you might need:\n",
    " - https://www.tensorflow.org/api_docs/python/tf/keras/\n",
    " - https://keras.io/api/\n",
    "\n",
    "Contain everything about:\n",
    "  - Model building: Activations, Losses, Optimizers, Regularization\n",
    "  - Data processing\n",
    "  - Pretrained models and datasets\n",
    "  - Automatic differentiation\n",
    "  - ...\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model speficication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three APIs for building the model\n",
    "   - sequential - easy to code, but less flexible - we will use it sometimes\n",
    "   - functional - flexible and still easy to code - we will use it the most\n",
    "   - model subclassing - rather complicated and not very much used - we will skip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/sequential_model)\n",
    "\n",
    "Easy to code but <span style=\"color:red\"> NOT </span> appropriate when:\n",
    "\n",
    "- Your model has multiple inputs or multiple outputs\n",
    "- Any of your layers has multiple inputs or multiple outputs\n",
    "- You need to do layer sharing\n",
    "- You want non-linear topology (e.g. a residual connection, a multi-branch model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification A)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer([X_train.shape[1],]), # Create input layer with 'input data' neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"), # Create hidden layer with 10 neurons and ReLU activation\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"), # Create output layer with one neuron and sigmoid activation\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "#na vektor urobí výpočet a vyhodí jednu hodnotu\n",
    "#v nákrese modela budeme mať maticu, ktorá reprezentuje prechod z vektora na 10 uzlov\n",
    "#layer 0. matica 10x8 bias 10\n",
    "# 11, lebo zacinam s 10 dimenzionalnym vektorom\n",
    "#90 lebo 10x8 + 10 bias\n",
    "#tu sú všetky parametre trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Specification B)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(X_train.shape[1],)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(https://www.tensorflow.org/guide/keras/functional)\n",
    "\n",
    "The Keras functional API is a way to create models that are more flexible than the tf.keras.Sequential API. The functional API can handle models with non-linear topology, shared layers, and even multiple inputs or outputs.\n",
    "\n",
    "The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "hidden = tf.keras.layers.Dense(10)(inputs)#vlozim ho do hidden\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "hidden = tf.keras.layers.Dense(1)(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(hidden)#toto mi z toho urobi jednodimenzionalny vystup\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='Model')\n",
    "\n",
    "#konstrukteru neposielam vsetky layers vopred, ale najprv vezmem inouts a dam ho ako argument dalsiemu layeru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu (TFOpLambda)     (None, 10)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid (TFOpLambda  (None, 1)                0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#konstruovali sme rovnaky model, parametry su dimenzionalitou rovnake ako predtym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "# TODO: To make the following line work you need to install graphviz (if you have not done so in one of the previous classes)\n",
    "# 1) follow the instructions https://graphviz.gitlab.io/download/?fbclid=IwAR1V-lrRhho5rSfBVYXYISsighqRwOCOgMHLmL_DclkQrPtMXQaKj3mFcqs\n",
    "# 2) this notebook has been tested with version 8.0.3\n",
    "# 3) make sure you add it to the PATH variable (you are specifically asked during the installation) at least for local user\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with selected optimizer, loss and metrics\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(), # Several other possibilities for optimizers \n",
    "        loss=tf.losses.BinaryCrossentropy(), # Select the proper loss for the task\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()], # Select the proper metrics for the task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Bias of the last layers:\n",
      "[0.]\n",
      "\n",
      ">>> Kernel of the last layers:\n",
      "[[-0.72893476]\n",
      " [-0.71156394]\n",
      " [-0.2425799 ]\n",
      " [-0.6511235 ]\n",
      " [ 0.37352353]\n",
      " [-0.68818015]\n",
      " [ 0.34182936]\n",
      " [ 0.00153458]\n",
      " [-0.3081322 ]\n",
      " [-0.35564047]]\n",
      "\n",
      ">>> Bias of the first layers:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      ">>> Kernel of the first layers:\n",
      "[[-0.31383747  0.06594914 -0.29382563  0.5652292  -0.54854995 -0.54845333\n",
      "   0.22560358 -0.30288085 -0.52501136 -0.4196092 ]\n",
      " [-0.44453394  0.20297885  0.28307647 -0.39552096 -0.36806387 -0.293498\n",
      "   0.19550467  0.00085616 -0.4780521   0.04681826]\n",
      " [-0.46890563  0.21891373  0.54611063 -0.04934472 -0.13326505 -0.1936644\n",
      "   0.28158736 -0.37767726  0.25715292 -0.0426743 ]\n",
      " [-0.09494659  0.35307693 -0.4111284   0.33889478  0.5138445   0.02470738\n",
      "   0.45941424  0.10407823 -0.41524112  0.10758251]\n",
      " [ 0.42415273 -0.46851316 -0.24430388  0.4363283  -0.5718684   0.40568852\n",
      "  -0.16792339  0.19183308  0.50850534 -0.45830676]\n",
      " [-0.12345082  0.45700085 -0.4183625   0.4960717   0.08358777 -0.35971847\n",
      "   0.11719882 -0.12169287 -0.31820473  0.39845377]\n",
      " [ 0.36298615  0.53550863  0.18667352  0.54735935  0.19619018  0.21113604\n",
      "   0.16783047  0.44335604  0.35318047  0.34967917]\n",
      " [ 0.5096859  -0.45390937 -0.19798389 -0.05921525 -0.06139606 -0.36974552\n",
      "  -0.4150418  -0.53526455  0.5407231  -0.22484359]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n>>> Bias of the last layers:')\n",
    "print(model.layers[3].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the last layers:')\n",
    "print(model.layers[3].weights[0].numpy())\n",
    "\n",
    "print('\\n>>> Bias of the first layers:')\n",
    "print(model.layers[1].weights[1].numpy())\n",
    "\n",
    "print('\\n>>> Kernel of the first layers:')\n",
    "print(model.layers[1].weights[0].numpy())#kernel značí maticu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 2s 2ms/step - loss: 0.7865 - auc: 0.6481 - binary_accuracy: 0.6016\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5029 - auc: 0.8516 - binary_accuracy: 0.7720\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4298 - auc: 0.8969 - binary_accuracy: 0.8131\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3867 - auc: 0.9164 - binary_accuracy: 0.8436\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3578 - auc: 0.9270 - binary_accuracy: 0.8602\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3366 - auc: 0.9344 - binary_accuracy: 0.8723\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3203 - auc: 0.9401 - binary_accuracy: 0.8797\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.3076 - auc: 0.9442 - binary_accuracy: 0.8831\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2985 - auc: 0.9467 - binary_accuracy: 0.8869\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2914 - auc: 0.9488 - binary_accuracy: 0.8894\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2855 - auc: 0.9506 - binary_accuracy: 0.8920\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2799 - auc: 0.9524 - binary_accuracy: 0.8942\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2746 - auc: 0.9542 - binary_accuracy: 0.8968\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2696 - auc: 0.9558 - binary_accuracy: 0.9006\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2648 - auc: 0.9575 - binary_accuracy: 0.9023\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2607 - auc: 0.9587 - binary_accuracy: 0.9040\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2565 - auc: 0.9601 - binary_accuracy: 0.9060\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2532 - auc: 0.9613 - binary_accuracy: 0.9063\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2501 - auc: 0.9621 - binary_accuracy: 0.9079\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2474 - auc: 0.9630 - binary_accuracy: 0.9080\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2451 - auc: 0.9636 - binary_accuracy: 0.9080\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2431 - auc: 0.9642 - binary_accuracy: 0.9075\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2410 - auc: 0.9648 - binary_accuracy: 0.9086\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2396 - auc: 0.9652 - binary_accuracy: 0.9082\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2380 - auc: 0.9656 - binary_accuracy: 0.9092\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2365 - auc: 0.9661 - binary_accuracy: 0.9098\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2348 - auc: 0.9665 - binary_accuracy: 0.9103\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2336 - auc: 0.9669 - binary_accuracy: 0.9099\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2323 - auc: 0.9673 - binary_accuracy: 0.9102\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2310 - auc: 0.9676 - binary_accuracy: 0.9109\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2297 - auc: 0.9680 - binary_accuracy: 0.9106\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2285 - auc: 0.9684 - binary_accuracy: 0.9111\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2273 - auc: 0.9687 - binary_accuracy: 0.9117\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2263 - auc: 0.9690 - binary_accuracy: 0.9116\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2251 - auc: 0.9693 - binary_accuracy: 0.9130\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2241 - auc: 0.9697 - binary_accuracy: 0.9124\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2231 - auc: 0.9699 - binary_accuracy: 0.9125\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2222 - auc: 0.9701 - binary_accuracy: 0.9130\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2216 - auc: 0.9704 - binary_accuracy: 0.9130\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2205 - auc: 0.9707 - binary_accuracy: 0.9127\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2199 - auc: 0.9708 - binary_accuracy: 0.9130\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2193 - auc: 0.9710 - binary_accuracy: 0.9134\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2183 - auc: 0.9712 - binary_accuracy: 0.9137\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2180 - auc: 0.9714 - binary_accuracy: 0.9140\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2171 - auc: 0.9717 - binary_accuracy: 0.9127\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2165 - auc: 0.9717 - binary_accuracy: 0.9137\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2159 - auc: 0.9720 - binary_accuracy: 0.9137\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2152 - auc: 0.9722 - binary_accuracy: 0.9151\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 0.2149 - auc: 0.9721 - binary_accuracy: 0.9135\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2142 - auc: 0.9724 - binary_accuracy: 0.9143\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2139 - auc: 0.9725 - binary_accuracy: 0.9142\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2133 - auc: 0.9726 - binary_accuracy: 0.9152\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2125 - auc: 0.9729 - binary_accuracy: 0.9145\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2124 - auc: 0.9729 - binary_accuracy: 0.9164\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2118 - auc: 0.9730 - binary_accuracy: 0.9157\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2115 - auc: 0.9731 - binary_accuracy: 0.9161\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2110 - auc: 0.9733 - binary_accuracy: 0.9163\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2109 - auc: 0.9733 - binary_accuracy: 0.9171\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2104 - auc: 0.9734 - binary_accuracy: 0.9178\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2104 - auc: 0.9734 - binary_accuracy: 0.9168\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2100 - auc: 0.9736 - binary_accuracy: 0.9178\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2098 - auc: 0.9736 - binary_accuracy: 0.9161\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2094 - auc: 0.9738 - binary_accuracy: 0.9187\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2088 - auc: 0.9739 - binary_accuracy: 0.9182\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2090 - auc: 0.9738 - binary_accuracy: 0.9185\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2088 - auc: 0.9739 - binary_accuracy: 0.9186\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2084 - auc: 0.9740 - binary_accuracy: 0.9195\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2082 - auc: 0.9740 - binary_accuracy: 0.9185\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2079 - auc: 0.9741 - binary_accuracy: 0.9184\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2077 - auc: 0.9743 - binary_accuracy: 0.9195\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2075 - auc: 0.9742 - binary_accuracy: 0.9193\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.2074 - auc: 0.9743 - binary_accuracy: 0.9185\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2073 - auc: 0.9743 - binary_accuracy: 0.9205\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2072 - auc: 0.9744 - binary_accuracy: 0.9205\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2070 - auc: 0.9743 - binary_accuracy: 0.9203\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2067 - auc: 0.9744 - binary_accuracy: 0.9199\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2069 - auc: 0.9744 - binary_accuracy: 0.9200\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2067 - auc: 0.9746 - binary_accuracy: 0.9201\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2066 - auc: 0.9744 - binary_accuracy: 0.9196\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2065 - auc: 0.9745 - binary_accuracy: 0.9219\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2063 - auc: 0.9746 - binary_accuracy: 0.9212\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2062 - auc: 0.9745 - binary_accuracy: 0.9211\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2060 - auc: 0.9745 - binary_accuracy: 0.9211\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2058 - auc: 0.9747 - binary_accuracy: 0.9212\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2060 - auc: 0.9746 - binary_accuracy: 0.9207\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2058 - auc: 0.9747 - binary_accuracy: 0.9211\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2055 - auc: 0.9747 - binary_accuracy: 0.9211\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2056 - auc: 0.9747 - binary_accuracy: 0.9213\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2052 - auc: 0.9748 - binary_accuracy: 0.9218\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2053 - auc: 0.9748 - binary_accuracy: 0.9206\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2050 - auc: 0.9748 - binary_accuracy: 0.9217\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2048 - auc: 0.9750 - binary_accuracy: 0.9223\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2050 - auc: 0.9749 - binary_accuracy: 0.9225\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2046 - auc: 0.9750 - binary_accuracy: 0.9217\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2044 - auc: 0.9751 - binary_accuracy: 0.9223\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2046 - auc: 0.9750 - binary_accuracy: 0.9217\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2041 - auc: 0.9751 - binary_accuracy: 0.9230\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2040 - auc: 0.9752 - binary_accuracy: 0.9223\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2041 - auc: 0.9752 - binary_accuracy: 0.9230\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.2039 - auc: 0.9751 - binary_accuracy: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24154a50640>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with default setting\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=100)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 3ms/step - loss: 0.2265 - auc: 0.9693 - binary_accuracy: 0.9135\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and predict for the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 0.36\n",
      "0 - 0.20\n",
      "0 - 0.64\n",
      "1 - 0.98\n",
      "0 - 0.00\n",
      "0 - 0.00\n",
      "1 - 0.97\n",
      "0 - 0.00\n",
      "1 - 1.00\n",
      "1 - 1.00\n"
     ]
    }
   ],
   "source": [
    "for pred, true in zip(test_pred, y_test[0:10]):\n",
    "    print('{} - {:.2f}'.format(true, pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add early stopping and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RegularizedModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " tf.math.sigmoid_1 (TFOpLamb  (None, 1)                0         \n",
      " da)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "# Hidden layer with regularization and ReLU\n",
    "hidden = tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)\n",
    "hidden = tf.keras.activations.relu(hidden)\n",
    "\n",
    "# Output layer with regularization and sigmoid\n",
    "outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(0.001))(hidden)\n",
    "outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "model.compile(\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        loss=tf.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "400/400 [==============================] - 2s 3ms/step - loss: 0.5382 - auc_1: 0.8246 - binary_accuracy: 0.7381 - val_loss: 0.4406 - val_auc_1: 0.8964 - val_binary_accuracy: 0.8034\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.4196 - auc_1: 0.9041 - binary_accuracy: 0.8213 - val_loss: 0.3840 - val_auc_1: 0.9239 - val_binary_accuracy: 0.8472\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3727 - auc_1: 0.9268 - binary_accuracy: 0.8528 - val_loss: 0.3435 - val_auc_1: 0.9389 - val_binary_accuracy: 0.8753\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3358 - auc_1: 0.9415 - binary_accuracy: 0.8723 - val_loss: 0.3166 - val_auc_1: 0.9489 - val_binary_accuracy: 0.8869\n",
      "Epoch 5/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.3125 - auc_1: 0.9499 - binary_accuracy: 0.8848 - val_loss: 0.3019 - val_auc_1: 0.9539 - val_binary_accuracy: 0.8894\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2982 - auc_1: 0.9549 - binary_accuracy: 0.8934 - val_loss: 0.2923 - val_auc_1: 0.9569 - val_binary_accuracy: 0.8925\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2893 - auc_1: 0.9579 - binary_accuracy: 0.8979 - val_loss: 0.2864 - val_auc_1: 0.9588 - val_binary_accuracy: 0.8947\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2833 - auc_1: 0.9599 - binary_accuracy: 0.8993 - val_loss: 0.2818 - val_auc_1: 0.9602 - val_binary_accuracy: 0.8963\n",
      "Epoch 9/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2789 - auc_1: 0.9613 - binary_accuracy: 0.9019 - val_loss: 0.2788 - val_auc_1: 0.9614 - val_binary_accuracy: 0.8938\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2753 - auc_1: 0.9625 - binary_accuracy: 0.9034 - val_loss: 0.2778 - val_auc_1: 0.9620 - val_binary_accuracy: 0.8947\n",
      "Epoch 11/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2726 - auc_1: 0.9635 - binary_accuracy: 0.9045 - val_loss: 0.2756 - val_auc_1: 0.9629 - val_binary_accuracy: 0.8950\n",
      "Epoch 12/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2702 - auc_1: 0.9641 - binary_accuracy: 0.9055 - val_loss: 0.2726 - val_auc_1: 0.9638 - val_binary_accuracy: 0.8969\n",
      "Epoch 13/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2681 - auc_1: 0.9650 - binary_accuracy: 0.9058 - val_loss: 0.2708 - val_auc_1: 0.9646 - val_binary_accuracy: 0.8969\n",
      "Epoch 14/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2659 - auc_1: 0.9658 - binary_accuracy: 0.9073 - val_loss: 0.2677 - val_auc_1: 0.9654 - val_binary_accuracy: 0.9009\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2637 - auc_1: 0.9666 - binary_accuracy: 0.9091 - val_loss: 0.2664 - val_auc_1: 0.9659 - val_binary_accuracy: 0.9003\n",
      "Epoch 16/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2620 - auc_1: 0.9673 - binary_accuracy: 0.9090 - val_loss: 0.2647 - val_auc_1: 0.9667 - val_binary_accuracy: 0.9044\n",
      "Epoch 17/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2599 - auc_1: 0.9681 - binary_accuracy: 0.9111 - val_loss: 0.2622 - val_auc_1: 0.9674 - val_binary_accuracy: 0.9072\n",
      "Epoch 18/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2580 - auc_1: 0.9687 - binary_accuracy: 0.9125 - val_loss: 0.2611 - val_auc_1: 0.9682 - val_binary_accuracy: 0.9084\n",
      "Epoch 19/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2561 - auc_1: 0.9695 - binary_accuracy: 0.9141 - val_loss: 0.2598 - val_auc_1: 0.9688 - val_binary_accuracy: 0.9059\n",
      "Epoch 20/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2545 - auc_1: 0.9701 - binary_accuracy: 0.9155 - val_loss: 0.2582 - val_auc_1: 0.9692 - val_binary_accuracy: 0.9100\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2528 - auc_1: 0.9706 - binary_accuracy: 0.9166 - val_loss: 0.2547 - val_auc_1: 0.9702 - val_binary_accuracy: 0.9125\n",
      "Epoch 22/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2517 - auc_1: 0.9710 - binary_accuracy: 0.9172 - val_loss: 0.2538 - val_auc_1: 0.9707 - val_binary_accuracy: 0.9156\n",
      "Epoch 23/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2503 - auc_1: 0.9716 - binary_accuracy: 0.9170 - val_loss: 0.2524 - val_auc_1: 0.9714 - val_binary_accuracy: 0.9150\n",
      "Epoch 24/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2491 - auc_1: 0.9720 - binary_accuracy: 0.9191 - val_loss: 0.2516 - val_auc_1: 0.9719 - val_binary_accuracy: 0.9162\n",
      "Epoch 25/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2483 - auc_1: 0.9725 - binary_accuracy: 0.9203 - val_loss: 0.2496 - val_auc_1: 0.9723 - val_binary_accuracy: 0.9169\n",
      "Epoch 26/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2469 - auc_1: 0.9731 - binary_accuracy: 0.9225 - val_loss: 0.2499 - val_auc_1: 0.9720 - val_binary_accuracy: 0.9191\n",
      "Epoch 27/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2461 - auc_1: 0.9733 - binary_accuracy: 0.9220 - val_loss: 0.2485 - val_auc_1: 0.9728 - val_binary_accuracy: 0.9178\n",
      "Epoch 28/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2453 - auc_1: 0.9737 - binary_accuracy: 0.9228 - val_loss: 0.2487 - val_auc_1: 0.9732 - val_binary_accuracy: 0.9178\n",
      "Epoch 29/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2438 - auc_1: 0.9743 - binary_accuracy: 0.9240 - val_loss: 0.2459 - val_auc_1: 0.9730 - val_binary_accuracy: 0.9216\n",
      "Epoch 30/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2435 - auc_1: 0.9743 - binary_accuracy: 0.9248 - val_loss: 0.2451 - val_auc_1: 0.9740 - val_binary_accuracy: 0.9225\n",
      "Epoch 31/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2427 - auc_1: 0.9747 - binary_accuracy: 0.9254 - val_loss: 0.2448 - val_auc_1: 0.9743 - val_binary_accuracy: 0.9212\n",
      "Epoch 32/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2417 - auc_1: 0.9751 - binary_accuracy: 0.9252 - val_loss: 0.2437 - val_auc_1: 0.9744 - val_binary_accuracy: 0.9231\n",
      "Epoch 33/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2410 - auc_1: 0.9753 - binary_accuracy: 0.9280 - val_loss: 0.2426 - val_auc_1: 0.9745 - val_binary_accuracy: 0.9234\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2403 - auc_1: 0.9757 - binary_accuracy: 0.9286 - val_loss: 0.2430 - val_auc_1: 0.9749 - val_binary_accuracy: 0.9275\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2396 - auc_1: 0.9758 - binary_accuracy: 0.9283 - val_loss: 0.2429 - val_auc_1: 0.9750 - val_binary_accuracy: 0.9272\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2391 - auc_1: 0.9762 - binary_accuracy: 0.9302 - val_loss: 0.2426 - val_auc_1: 0.9756 - val_binary_accuracy: 0.9250\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2389 - auc_1: 0.9762 - binary_accuracy: 0.9308 - val_loss: 0.2415 - val_auc_1: 0.9757 - val_binary_accuracy: 0.9262\n",
      "Epoch 38/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2380 - auc_1: 0.9766 - binary_accuracy: 0.9316 - val_loss: 0.2410 - val_auc_1: 0.9759 - val_binary_accuracy: 0.9266\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2379 - auc_1: 0.9768 - binary_accuracy: 0.9311 - val_loss: 0.2394 - val_auc_1: 0.9759 - val_binary_accuracy: 0.9262\n",
      "Epoch 40/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2372 - auc_1: 0.9769 - binary_accuracy: 0.9317 - val_loss: 0.2399 - val_auc_1: 0.9761 - val_binary_accuracy: 0.9281\n",
      "Epoch 41/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2365 - auc_1: 0.9773 - binary_accuracy: 0.9316 - val_loss: 0.2401 - val_auc_1: 0.9759 - val_binary_accuracy: 0.9281\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2362 - auc_1: 0.9772 - binary_accuracy: 0.9316 - val_loss: 0.2407 - val_auc_1: 0.9762 - val_binary_accuracy: 0.9259\n",
      "Epoch 43/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2359 - auc_1: 0.9774 - binary_accuracy: 0.9342 - val_loss: 0.2393 - val_auc_1: 0.9762 - val_binary_accuracy: 0.9291\n",
      "Epoch 44/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2354 - auc_1: 0.9776 - binary_accuracy: 0.9336 - val_loss: 0.2387 - val_auc_1: 0.9763 - val_binary_accuracy: 0.9297\n",
      "Epoch 45/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2353 - auc_1: 0.9776 - binary_accuracy: 0.9341 - val_loss: 0.2394 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9306\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2346 - auc_1: 0.9779 - binary_accuracy: 0.9334 - val_loss: 0.2378 - val_auc_1: 0.9764 - val_binary_accuracy: 0.9316\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2345 - auc_1: 0.9778 - binary_accuracy: 0.9348 - val_loss: 0.2382 - val_auc_1: 0.9767 - val_binary_accuracy: 0.9300\n",
      "Epoch 48/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2341 - auc_1: 0.9781 - binary_accuracy: 0.9343 - val_loss: 0.2374 - val_auc_1: 0.9764 - val_binary_accuracy: 0.9334\n",
      "Epoch 49/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2338 - auc_1: 0.9782 - binary_accuracy: 0.9349 - val_loss: 0.2367 - val_auc_1: 0.9768 - val_binary_accuracy: 0.9328\n",
      "Epoch 50/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2335 - auc_1: 0.9782 - binary_accuracy: 0.9341 - val_loss: 0.2373 - val_auc_1: 0.9768 - val_binary_accuracy: 0.9328\n",
      "Epoch 51/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2332 - auc_1: 0.9783 - binary_accuracy: 0.9355 - val_loss: 0.2366 - val_auc_1: 0.9767 - val_binary_accuracy: 0.9312\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2331 - auc_1: 0.9783 - binary_accuracy: 0.9345 - val_loss: 0.2373 - val_auc_1: 0.9775 - val_binary_accuracy: 0.9344\n",
      "Epoch 53/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2324 - auc_1: 0.9786 - binary_accuracy: 0.9365 - val_loss: 0.2365 - val_auc_1: 0.9774 - val_binary_accuracy: 0.9325\n",
      "Epoch 54/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2319 - auc_1: 0.9789 - binary_accuracy: 0.9372 - val_loss: 0.2365 - val_auc_1: 0.9769 - val_binary_accuracy: 0.9325\n",
      "Epoch 55/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2322 - auc_1: 0.9787 - binary_accuracy: 0.9360 - val_loss: 0.2360 - val_auc_1: 0.9776 - val_binary_accuracy: 0.9341\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2319 - auc_1: 0.9789 - binary_accuracy: 0.9360 - val_loss: 0.2365 - val_auc_1: 0.9776 - val_binary_accuracy: 0.9322\n",
      "Epoch 57/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2315 - auc_1: 0.9790 - binary_accuracy: 0.9364 - val_loss: 0.2368 - val_auc_1: 0.9774 - val_binary_accuracy: 0.9350\n",
      "Epoch 58/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2313 - auc_1: 0.9791 - binary_accuracy: 0.9368 - val_loss: 0.2366 - val_auc_1: 0.9774 - val_binary_accuracy: 0.9337\n",
      "Epoch 59/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2310 - auc_1: 0.9791 - binary_accuracy: 0.9370 - val_loss: 0.2354 - val_auc_1: 0.9777 - val_binary_accuracy: 0.9331\n",
      "Epoch 60/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2312 - auc_1: 0.9791 - binary_accuracy: 0.9366 - val_loss: 0.2349 - val_auc_1: 0.9779 - val_binary_accuracy: 0.9350\n",
      "Epoch 61/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2309 - auc_1: 0.9792 - binary_accuracy: 0.9384 - val_loss: 0.2348 - val_auc_1: 0.9778 - val_binary_accuracy: 0.9325\n",
      "Epoch 62/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2307 - auc_1: 0.9793 - binary_accuracy: 0.9367 - val_loss: 0.2347 - val_auc_1: 0.9778 - val_binary_accuracy: 0.9337\n",
      "Epoch 63/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2306 - auc_1: 0.9794 - binary_accuracy: 0.9383 - val_loss: 0.2357 - val_auc_1: 0.9783 - val_binary_accuracy: 0.9328\n",
      "Epoch 64/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2306 - auc_1: 0.9795 - binary_accuracy: 0.9377 - val_loss: 0.2349 - val_auc_1: 0.9779 - val_binary_accuracy: 0.9359\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2306 - auc_1: 0.9793 - binary_accuracy: 0.9379 - val_loss: 0.2349 - val_auc_1: 0.9781 - val_binary_accuracy: 0.9347\n",
      "Epoch 66/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2301 - auc_1: 0.9797 - binary_accuracy: 0.9389 - val_loss: 0.2345 - val_auc_1: 0.9779 - val_binary_accuracy: 0.9328\n",
      "Epoch 67/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2300 - auc_1: 0.9796 - binary_accuracy: 0.9373 - val_loss: 0.2352 - val_auc_1: 0.9781 - val_binary_accuracy: 0.9344\n",
      "Epoch 68/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2300 - auc_1: 0.9797 - binary_accuracy: 0.9386 - val_loss: 0.2349 - val_auc_1: 0.9783 - val_binary_accuracy: 0.9337\n",
      "Epoch 69/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2300 - auc_1: 0.9796 - binary_accuracy: 0.9386 - val_loss: 0.2348 - val_auc_1: 0.9783 - val_binary_accuracy: 0.9344\n",
      "Epoch 70/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2298 - auc_1: 0.9798 - binary_accuracy: 0.9380 - val_loss: 0.2354 - val_auc_1: 0.9779 - val_binary_accuracy: 0.9347\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2301 - auc_1: 0.9797 - binary_accuracy: 0.9388 - val_loss: 0.2343 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9331\n",
      "Epoch 72/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2296 - auc_1: 0.9800 - binary_accuracy: 0.9392 - val_loss: 0.2343 - val_auc_1: 0.9783 - val_binary_accuracy: 0.9353\n",
      "Epoch 73/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2295 - auc_1: 0.9799 - binary_accuracy: 0.9380 - val_loss: 0.2346 - val_auc_1: 0.9787 - val_binary_accuracy: 0.9337\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2294 - auc_1: 0.9799 - binary_accuracy: 0.9400 - val_loss: 0.2361 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9341\n",
      "Epoch 75/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2296 - auc_1: 0.9798 - binary_accuracy: 0.9386 - val_loss: 0.2346 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9341\n",
      "Epoch 76/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2297 - auc_1: 0.9801 - binary_accuracy: 0.9390 - val_loss: 0.2346 - val_auc_1: 0.9786 - val_binary_accuracy: 0.9369\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2292 - auc_1: 0.9799 - binary_accuracy: 0.9391 - val_loss: 0.2353 - val_auc_1: 0.9787 - val_binary_accuracy: 0.9353\n",
      "Epoch 78/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2292 - auc_1: 0.9802 - binary_accuracy: 0.9390 - val_loss: 0.2338 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9334\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2291 - auc_1: 0.9801 - binary_accuracy: 0.9387 - val_loss: 0.2347 - val_auc_1: 0.9786 - val_binary_accuracy: 0.9341\n",
      "Epoch 80/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2292 - auc_1: 0.9801 - binary_accuracy: 0.9405 - val_loss: 0.2347 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9356\n",
      "Epoch 81/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2293 - auc_1: 0.9800 - binary_accuracy: 0.9388 - val_loss: 0.2350 - val_auc_1: 0.9787 - val_binary_accuracy: 0.9347\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2292 - auc_1: 0.9802 - binary_accuracy: 0.9388 - val_loss: 0.2344 - val_auc_1: 0.9789 - val_binary_accuracy: 0.9347\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2290 - auc_1: 0.9803 - binary_accuracy: 0.9385 - val_loss: 0.2341 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9322\n",
      "Epoch 84/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2291 - auc_1: 0.9802 - binary_accuracy: 0.9395 - val_loss: 0.2343 - val_auc_1: 0.9785 - val_binary_accuracy: 0.9353\n",
      "Epoch 85/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2289 - auc_1: 0.9803 - binary_accuracy: 0.9381 - val_loss: 0.2354 - val_auc_1: 0.9780 - val_binary_accuracy: 0.9362\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2290 - auc_1: 0.9803 - binary_accuracy: 0.9401 - val_loss: 0.2335 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9353\n",
      "Epoch 87/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2289 - auc_1: 0.9802 - binary_accuracy: 0.9391 - val_loss: 0.2341 - val_auc_1: 0.9790 - val_binary_accuracy: 0.9366\n",
      "Epoch 88/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2286 - auc_1: 0.9804 - binary_accuracy: 0.9395 - val_loss: 0.2353 - val_auc_1: 0.9791 - val_binary_accuracy: 0.9344\n",
      "Epoch 89/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2290 - auc_1: 0.9803 - binary_accuracy: 0.9395 - val_loss: 0.2346 - val_auc_1: 0.9790 - val_binary_accuracy: 0.9356\n",
      "Epoch 90/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2287 - auc_1: 0.9805 - binary_accuracy: 0.9381 - val_loss: 0.2336 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9366\n",
      "Epoch 91/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2289 - auc_1: 0.9803 - binary_accuracy: 0.9387 - val_loss: 0.2347 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9359\n",
      "Epoch 92/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2287 - auc_1: 0.9805 - binary_accuracy: 0.9401 - val_loss: 0.2341 - val_auc_1: 0.9789 - val_binary_accuracy: 0.9362\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2285 - auc_1: 0.9805 - binary_accuracy: 0.9402 - val_loss: 0.2343 - val_auc_1: 0.9789 - val_binary_accuracy: 0.9350\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2288 - auc_1: 0.9805 - binary_accuracy: 0.9401 - val_loss: 0.2339 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9353\n",
      "Epoch 95/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2288 - auc_1: 0.9804 - binary_accuracy: 0.9398 - val_loss: 0.2340 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9366\n",
      "Epoch 96/200\n",
      "400/400 [==============================] - 1s 2ms/step - loss: 0.2286 - auc_1: 0.9804 - binary_accuracy: 0.9398 - val_loss: 0.2338 - val_auc_1: 0.9789 - val_binary_accuracy: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241548e4a60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          callbacks=[early_call])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch and Tensorboard\n",
    "Run gridsearch over hidden layer size, L2 regularization, activation, check the outputs in Tensorboard\n",
    "\n",
    "I recommend not to run Tensorboard from Jupyter notebook but from terminal directly\n",
    "\n",
    "use \"tensorboard --logdir logs\" in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 2s 4ms/step - loss: 1.0569 - AUC: 0.7086 - binary_accuracy: 0.5770 - val_loss: 0.8187 - val_AUC: 0.7528 - val_binary_accuracy: 0.6256\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7320 - AUC: 0.7577 - binary_accuracy: 0.6484 - val_loss: 0.6483 - val_AUC: 0.7970 - val_binary_accuracy: 0.7072\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6219 - AUC: 0.8001 - binary_accuracy: 0.7216 - val_loss: 0.5857 - val_AUC: 0.8277 - val_binary_accuracy: 0.7534\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5739 - AUC: 0.8227 - binary_accuracy: 0.7573 - val_loss: 0.5507 - val_AUC: 0.8412 - val_binary_accuracy: 0.7763\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5462 - AUC: 0.8340 - binary_accuracy: 0.7774 - val_loss: 0.5307 - val_AUC: 0.8445 - val_binary_accuracy: 0.7966\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5303 - AUC: 0.8369 - binary_accuracy: 0.7845 - val_loss: 0.5188 - val_AUC: 0.8459 - val_binary_accuracy: 0.8003\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5209 - AUC: 0.8384 - binary_accuracy: 0.7898 - val_loss: 0.5116 - val_AUC: 0.8464 - val_binary_accuracy: 0.8056\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5150 - AUC: 0.8399 - binary_accuracy: 0.7930 - val_loss: 0.5067 - val_AUC: 0.8465 - val_binary_accuracy: 0.8069\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5109 - AUC: 0.8393 - binary_accuracy: 0.7963 - val_loss: 0.5030 - val_AUC: 0.8467 - val_binary_accuracy: 0.8087\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5080 - AUC: 0.8395 - binary_accuracy: 0.7975 - val_loss: 0.5006 - val_AUC: 0.8478 - val_binary_accuracy: 0.8087\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.1182 - AUC: 0.5062 - binary_accuracy: 0.5073 - val_loss: 0.8651 - val_AUC: 0.5683 - val_binary_accuracy: 0.5272\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7605 - AUC: 0.6460 - binary_accuracy: 0.5876 - val_loss: 0.6756 - val_AUC: 0.7388 - val_binary_accuracy: 0.6687\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6391 - AUC: 0.7903 - binary_accuracy: 0.7144 - val_loss: 0.5992 - val_AUC: 0.8382 - val_binary_accuracy: 0.7575\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5891 - AUC: 0.8458 - binary_accuracy: 0.7708 - val_loss: 0.5648 - val_AUC: 0.8712 - val_binary_accuracy: 0.7959\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5634 - AUC: 0.8645 - binary_accuracy: 0.7976 - val_loss: 0.5446 - val_AUC: 0.8805 - val_binary_accuracy: 0.8106\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5463 - AUC: 0.8699 - binary_accuracy: 0.8079 - val_loss: 0.5306 - val_AUC: 0.8829 - val_binary_accuracy: 0.8156\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5332 - AUC: 0.8740 - binary_accuracy: 0.8100 - val_loss: 0.5195 - val_AUC: 0.8844 - val_binary_accuracy: 0.8144\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5223 - AUC: 0.8784 - binary_accuracy: 0.8115 - val_loss: 0.5103 - val_AUC: 0.8874 - val_binary_accuracy: 0.8141\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5136 - AUC: 0.8817 - binary_accuracy: 0.8146 - val_loss: 0.5040 - val_AUC: 0.8878 - val_binary_accuracy: 0.8138\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5074 - AUC: 0.8843 - binary_accuracy: 0.8145 - val_loss: 0.4985 - val_AUC: 0.8902 - val_binary_accuracy: 0.8156\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7344 - AUC: 0.3626 - binary_accuracy: 0.4194 - val_loss: 0.7127 - val_AUC: 0.4418 - val_binary_accuracy: 0.4859\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7015 - AUC: 0.5146 - binary_accuracy: 0.5317 - val_loss: 0.6879 - val_AUC: 0.6112 - val_binary_accuracy: 0.5819\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6560 - AUC: 0.7620 - binary_accuracy: 0.6656 - val_loss: 0.6144 - val_AUC: 0.8408 - val_binary_accuracy: 0.7728\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5885 - AUC: 0.8420 - binary_accuracy: 0.7700 - val_loss: 0.5585 - val_AUC: 0.8583 - val_binary_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5500 - AUC: 0.8518 - binary_accuracy: 0.7802 - val_loss: 0.5291 - val_AUC: 0.8639 - val_binary_accuracy: 0.8022\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5290 - AUC: 0.8569 - binary_accuracy: 0.7830 - val_loss: 0.5124 - val_AUC: 0.8686 - val_binary_accuracy: 0.8069\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5164 - AUC: 0.8611 - binary_accuracy: 0.7867 - val_loss: 0.5018 - val_AUC: 0.8723 - val_binary_accuracy: 0.8081\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5084 - AUC: 0.8641 - binary_accuracy: 0.7873 - val_loss: 0.4953 - val_AUC: 0.8749 - val_binary_accuracy: 0.8097\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5030 - AUC: 0.8668 - binary_accuracy: 0.7898 - val_loss: 0.4901 - val_AUC: 0.8780 - val_binary_accuracy: 0.8091\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4990 - AUC: 0.8692 - binary_accuracy: 0.7910 - val_loss: 0.4869 - val_AUC: 0.8809 - val_binary_accuracy: 0.8091\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.9367 - AUC: 0.5496 - binary_accuracy: 0.5374 - val_loss: 0.7710 - val_AUC: 0.6337 - val_binary_accuracy: 0.5594\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6817 - AUC: 0.7283 - binary_accuracy: 0.6437 - val_loss: 0.6122 - val_AUC: 0.8133 - val_binary_accuracy: 0.7400\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5809 - AUC: 0.8463 - binary_accuracy: 0.7806 - val_loss: 0.5455 - val_AUC: 0.8761 - val_binary_accuracy: 0.8109\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5335 - AUC: 0.8820 - binary_accuracy: 0.8066 - val_loss: 0.5092 - val_AUC: 0.8970 - val_binary_accuracy: 0.8225\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5061 - AUC: 0.8955 - binary_accuracy: 0.8128 - val_loss: 0.4883 - val_AUC: 0.9060 - val_binary_accuracy: 0.8253\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4897 - AUC: 0.9032 - binary_accuracy: 0.8188 - val_loss: 0.4759 - val_AUC: 0.9124 - val_binary_accuracy: 0.8334\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4800 - AUC: 0.9076 - binary_accuracy: 0.8248 - val_loss: 0.4687 - val_AUC: 0.9169 - val_binary_accuracy: 0.8403\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4741 - AUC: 0.9113 - binary_accuracy: 0.8326 - val_loss: 0.4641 - val_AUC: 0.9195 - val_binary_accuracy: 0.8428\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4703 - AUC: 0.9136 - binary_accuracy: 0.8366 - val_loss: 0.4612 - val_AUC: 0.9220 - val_binary_accuracy: 0.8478\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.4676 - AUC: 0.9164 - binary_accuracy: 0.8416 - val_loss: 0.4592 - val_AUC: 0.9238 - val_binary_accuracy: 0.8519\n"
     ]
    }
   ],
   "source": [
    "# hidden_sizes = [2, 5, 10, 20, 50]\n",
    "# l2_regs = [0.01, 0.001, 0.0001]\n",
    "# activations = ['relu', 'tanh']\n",
    "\n",
    "hidden_sizes = [2, 5]\n",
    "l2_regs = [0.01]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "early_call = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', mode='max', patience=10, restore_best_weights=True)\n",
    "\n",
    "for activation in activations:\n",
    "    for l2_reg in l2_regs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            if activation == 'relu':\n",
    "                activate = tf.keras.activations.relu\n",
    "            elif activation == 'tanh':\n",
    "                activate = tf.keras.activations.tanh\n",
    "\n",
    "            # Create Tensorboard Callback\n",
    "            param_string = 'act-{},l2-{},hs-{}'.format(activation, l2_reg, hidden_size)\n",
    "            log_dir = 'logs/binary_classification_test/' + param_string\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "            # Input layer\n",
    "            inputs = tf.keras.Input(shape=(X_train.shape[1]))\n",
    "\n",
    "            # Hidden layer with regularization and ReLU\n",
    "            hidden = tf.keras.layers.Dense(hidden_size, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
    "            hidden = activate(hidden)\n",
    "\n",
    "            # Output layer with regularization and sigmoid\n",
    "            outputs = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(hidden)\n",
    "            outputs = tf.keras.activations.sigmoid(outputs)\n",
    "\n",
    "            model = tf.keras.Model(inputs=inputs, outputs=outputs, name='RegularizedModel')\n",
    "\n",
    "            model.compile(\n",
    "                    optimizer=tf.optimizers.Adam(),\n",
    "                    loss=tf.losses.BinaryCrossentropy(),\n",
    "                    metrics=[tf.keras.metrics.AUC(name='AUC'), tf.keras.metrics.BinaryAccuracy()],\n",
    "            )\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                      validation_data=(X_dev, y_dev),\n",
    "                      callbacks=[early_call, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a96273f87a7b4fba\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a96273f87a7b4fba\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs/binary_classification_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
